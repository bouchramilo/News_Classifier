# ğŸ“° News Article Classification Pipeline

## ğŸ“Œ Description du projet

Ce projet consiste Ã  concevoir et implÃ©menter un **systÃ¨me intelligent de classification automatique dâ€™articles dâ€™actualitÃ©** en utilisant les techniques de **Natural Language Processing (NLP)** et de **Machine Learning**.  
Lâ€™objectif est de classer les articles en **quatre catÃ©gories stratÃ©giques** : **World**, **Sports**, **Business** et **Sci/Tech**.

Le projet met en place une **pipeline NLP complÃ¨te et automatisÃ©e**, depuis le chargement des donnÃ©es jusquâ€™au dÃ©ploiement du modÃ¨le final dans une application **Streamlit**, avec une orchestration globale assurÃ©e par **Apache Airflow** et un stockage vectoriel via **ChromaDB**.

---

## ğŸš€ FonctionnalitÃ©s principales

- Chargement automatique du dataset **SetFit/ag_news** depuis Hugging Face  
- Analyse exploratoire des donnÃ©es (EDA)  
- PrÃ©traitement avancÃ© des textes (normalisation, nettoyage, suppression des stopwords, regex)  
- GÃ©nÃ©ration dâ€™embeddings avec **Sentence Transformers**  
- Stockage vectoriel des embeddings dans **ChromaDB** (train / test)  
- EntraÃ®nement et Ã©valuation de modÃ¨les de Machine Learning  
- VÃ©rification de lâ€™overfitting avec plusieurs mÃ©triques  
- Orchestration complÃ¨te du pipeline via **Airflow DAG**  
- DÃ©ploiement du modÃ¨le dans une interface interactive **Streamlit**  

---

## ğŸ—‚ï¸ Structure du projet
```bach
News_Classifier/
â”œâ”€â”€ Dockerfile # Image Docker pour containeriser le projet
â”œâ”€â”€ docker-compose.yaml # Orchestration des services (Airflow, app, etc.)
â”œâ”€â”€ README.md # Documentation du projet
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”‚
â”œâ”€â”€ accueil.py # Page dâ€™accueil Streamlit
â”œâ”€â”€ pages/
â”‚ â””â”€â”€ prediction.py # Interface Streamlit pour la prÃ©diction des articles
â”‚
â”œâ”€â”€ airflow/
â”‚ â””â”€â”€ dags/
â”‚ â””â”€â”€ pipeline_dag.py # DAG Airflow orchestrant toute la pipeline NLP
â”‚
â”œâ”€â”€ functions/
â”‚ â”œâ”€â”€ data_loader.py # Chargement des donnÃ©es depuis Hugging Face
â”‚ â”œâ”€â”€ analyse_exploratoire.py # Analyse exploratoire des donnÃ©es (EDA)
â”‚ â”œâ”€â”€ pretraitement_text.py # Nettoyage et normalisation des textes
â”‚ â”œâ”€â”€ embeddings.py # GÃ©nÃ©ration des embeddings NLP
â”‚ â”œâ”€â”€ entrainement.py # EntraÃ®nement et Ã©valuation des modÃ¨les ML
â”‚ â””â”€â”€ pipeline.py # Pipeline globale (ETL + ML)
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train/ # Base vectorielle ChromaDB (train)
â”‚ â”œâ”€â”€ test/ # Base vectorielle ChromaDB (test)
â”‚ â””â”€â”€ chroma_db/ # DonnÃ©es persistÃ©es ChromaDB
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ news_classifier.pkl # ModÃ¨le ML entraÃ®nÃ© et sauvegardÃ©
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ partie_1.ipynb # Exploration et tests initiaux
â”‚
â”œâ”€â”€ articles_test.ipynb # Tests de prÃ©diction sur des articles
â””â”€â”€ taches.ipynb # Suivi et organisation des tÃ¢ches
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python**
- **Hugging Face Datasets**
- **Pandas / NumPy**
- **NLTK / Regex**
- **Sentence Transformers**
- **paraphrase-multilingual-MiniLM-L12-v2**
- **Scikit-learn**
- **ChromaDB (Vector Database)**
- **Apache Airflow**
- **Streamlit**
- **Docker & Docker Compose**
- **Jupyter Notebook**

---

## ğŸ³ ExÃ©cution du projet avec Docker

### âœ… PrÃ©requis

- Docker  
- Docker Compose  

VÃ©rifier lâ€™installation :
```bash
docker --version
docker-compose --version
```

---

## âš™ï¸ Installation et exÃ©cution du projet

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/bouchramilo/News_Classifier.git
cd News_Classifier
```

### 2ï¸âƒ£ Construire et lancer les conteneurs

```bash
docker-compose up --build
```

Cette commande :

- construit lâ€™image Docker,
- dÃ©marre Airflow (scheduler + webserver),
- initialise la pipeline NLP,
- rend lâ€™application Streamlit accessible.

3ï¸âƒ£ AccÃ©der aux services
ğŸ”¹ Apache Airflow

- URL : `http://localhost:8080`
- Activer le DAG : pipeline_dag

ğŸ”¹ Application Streamlit

- URL : `http://localhost:8501`
- Permet de tester la classification dâ€™articles en temps rÃ©el

4ï¸âƒ£ ArrÃªter les conteneurs

```bash
docker-compose down
```

---
Fin ğŸ˜Š
